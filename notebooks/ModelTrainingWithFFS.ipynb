{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skopt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcfe948",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.read_csv(\"/path_to_ADNI_training_dataset.csv\")\n",
    "test=pd.read_csv(\"/path_to_ADNI_test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetAIBL=pd.read_csv(\"/path_to_AIBL_dataset.csv\")\n",
    "datasetOASIS=pd.read_csv(\"/path_to_OASIS_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e400d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.rename(columns={ \"Unnamed: 0\": \"PTID\" }, inplace = True)\n",
    "test.rename(columns={ \"Unnamed: 0\": \"PTID\" }, inplace = True)\n",
    "datasetAIBL.rename(columns={ \"Unnamed: 0\": \"PTID\" }, inplace = True)\n",
    "datasetOASIS.rename(columns={ \"Unnamed: 0\": \"PTID\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=training.replace([np.inf, -np.inf], np.nan)\n",
    "test=test.replace([np.inf, -np.inf], np.nan)\n",
    "datasetAIBL=datasetAIBL.replace([np.inf, -np.inf], np.nan)\n",
    "datasetOASIS=datasetOASIS.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=training.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(cls,trainDsX, trainDsY,validDsX,validDsY):\n",
    "    initial_features = trainDsX.columns.tolist()\n",
    "    best_features = []\n",
    "    act_accuracy=0\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features,dtype=np.float64)\n",
    "        for new_column in remaining_features:\n",
    "            model = cls.fit(trainDsX[best_features+[new_column]],trainDsY)\n",
    "            predValid=cls.predict(validDsX[best_features+[new_column]])\n",
    "            new_pval[new_column] = accuracy_score(validDsY, predValid)\n",
    "        maxaccuracy = new_pval.max()\n",
    "        if(maxaccuracy>act_accuracy):\n",
    "            best_features.append(new_pval.idxmax())\n",
    "            act_accuracy=maxaccuracy\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe119af",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams=[\"rf\",\"xgbTree\",\"rpart\",\"svmPoly\",\"svmRBF\",\"logReg\"]\n",
    "featureSet=[\"MRI+SocioDemography\",\"MRI+SocioDemography+Genetics\",\"MRI+SocioDemography+Genetics+kogTest\"]\n",
    "fsMethods=[\"yes\",\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f204808",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameCSV=\"/path_to_results_file.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1760221",
   "metadata": {},
   "outputs": [],
   "source": [
    "for featureSetSelected in featureSet:\n",
    "    for model in modelParams:\n",
    "        for selectMethod in fsMethods:\n",
    "            if(featureSetSelected==\"MRI+SocioDemography\"):\n",
    "                X_train=training.drop([\"separation\",\"DX\",\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\"], axis=1)\n",
    "                LE = LabelEncoder()\n",
    "                LE.fit(training[\"DX\"])\n",
    "                y_train=LE.transform(training[\"DX\"])\n",
    "                X_test=test.drop([\"separation\",\"DX\",\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\"], axis=1)\n",
    "                y_test=LE.transform(test[\"DX\"])\n",
    "                y_AIBL=LE.transform(datasetAIBL[\"DX\"])\n",
    "                y_OASIS=LE.transform(datasetOASIS[\"DX\"])\n",
    "            elif(featureSetSelected==\"MRI+SocioDemography+Genetics\"):\n",
    "                X_train=training.drop([\"separation\",\"DX\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\"], axis=1)\n",
    "                LE = LabelEncoder()\n",
    "                LE.fit(training[\"DX\"])\n",
    "                y_train=LE.transform(training[\"DX\"])\n",
    "                X_test=test.drop([\"separation\",\"DX\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\"], axis=1)\n",
    "                y_test=LE.transform(test[\"DX\"])\n",
    "                y_AIBL=LE.transform(datasetAIBL[\"DX\"])\n",
    "                y_OASIS=LE.transform(datasetOASIS[\"DX\"])\n",
    "            elif(featureSetSelected==\"MRI+SocioDemography+Genetics+kogTest\"):\n",
    "                X_train=training.drop([\"separation\",\"DX\"], axis=1)\n",
    "                LE = LabelEncoder()\n",
    "                LE.fit(training[\"DX\"])\n",
    "                y_train=LE.transform(training[\"DX\"])\n",
    "                X_test=test.drop([\"separation\",\"DX\"], axis=1)\n",
    "                y_test=LE.transform(test[\"DX\"])\n",
    "                y_AIBL=LE.transform(datasetAIBL[\"DX\"])\n",
    "                y_OASIS=LE.transform(datasetOASIS[\"DX\"])\n",
    "            train_MRI=training.drop([\"separation\",\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'], axis=1)\n",
    "            test_MRI=training.drop([\"separation\",\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'], axis=1)\n",
    "            trainValidSplit=splitDataset.splitTrainingValidationAndTestdataset(train_MRI,Percent_Test=0.2,Percent_Valid=0.0,groupVar=\"DX\",seed=101)\n",
    "\n",
    "\n",
    "            trainValidSplit=trainValidSplit.set_index('PTID')\n",
    "            \n",
    "            is_training_split=(trainValidSplit.separation.isin([\"training\"]))\n",
    "            training_MRI=trainValidSplit[is_training_split]\n",
    "            training_MRI=training_MRI.drop([\"separation\"],axis=1)\n",
    "            training_MRI_X=training_MRI.drop([\"DX\"], axis=1)\n",
    "            training_MRI_y=LE.transform(training_MRI[\"DX\"])\n",
    "            is_test_split=(trainValidSplit.separation==\"test\")\n",
    "            test_MRI=trainValidSplit[is_test_split]\n",
    "            test_MRI=test_MRI.drop([\"separation\"],axis=1)\n",
    "            test_MRI_X=test_MRI.drop([\"DX\"], axis=1)\n",
    "            test_MRI_y=LE.transform(test_MRI[\"DX\"])\n",
    "            numeric_features = training_MRI_X.columns.values.tolist()\n",
    "\n",
    "            numeric_transformer = Pipeline(\n",
    "                steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "            )\n",
    "\n",
    "            categorical_features = []\n",
    "            categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", numeric_transformer, numeric_features),\n",
    "                    (\"cat\", categorical_transformer, categorical_features),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            clf = preprocessor\n",
    "            clf.fit(training_MRI_X)\n",
    "            training_MRI_X_data=pd.DataFrame(clf.transform(training_MRI_X),columns=training_MRI_X.columns)\n",
    "            test_MRI_X_data=pd.DataFrame(clf.transform(test_MRI_X),columns=training_MRI_X.columns)\n",
    "            if(selectMethod==\"yes\"):\n",
    "                if (model==\"rf\"):\n",
    "                    cls=RandomForestClassifier(random_state=42)\n",
    "                if (model==\"xgbTree\"):\n",
    "                    cls=xgb.XGBClassifier(booster =\"gbtree\",n_jobs=5,random_state=42)\n",
    "                if (model==\"rpart\"):\n",
    "                    cls=DecisionTreeClassifier(random_state=42)\n",
    "                if (model==\"svmPoly\"):\n",
    "                    cls=SVC(kernel=\"poly\",random_state=42,probability=True)\n",
    "                if (model==\"svmRBF\"):\n",
    "                    cls=SVC(kernel=\"rbf\",random_state=42,probability=True)\n",
    "                if (model==\"logReg\"):\n",
    "                    cls= LogisticRegression(random_state=42)\n",
    "                selectedFeatures=forward_selection(cls,training_MRI_X_data, training_MRI_y,test_MRI_X_data,test_MRI_y)\n",
    "            if(selectMethod==\"no\"):\n",
    "                selectedFeatures=training_MRI_X_data.columns.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "            X_train_MRI=X_train.filter(selectedFeatures,axis=1)\n",
    "            X_train_Rest=X_train.filter([\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'],axis=1)\n",
    "\n",
    "            X_test_MRI=X_test.filter(selectedFeatures,axis=1)\n",
    "            X_test_Rest=X_test.filter([\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'],axis=1)\n",
    "\n",
    "            X_AIBL_MRI=datasetAIBL.filter(selectedFeatures,axis=1)\n",
    "            X_AIBL_Rest=datasetAIBL.filter([\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'],axis=1)\n",
    "            \n",
    "            X_OASIS_MRI=datasetOASIS.filter(selectedFeatures,axis=1)\n",
    "            X_OASIS_Rest=datasetOASIS.filter([\"APOE4\",\"LDELTOTAL\",\"LIMMTOTAL\",\"MMSCORE\",\"AGE\",\"PTEDUCAT\",'PTGENDER_Female'],axis=1)\n",
    "\n",
    "            \n",
    "            X_train_filtered = pd.concat([X_train_Rest.reset_index(drop=True), X_train_MRI.reset_index(drop=True)], axis=1)\n",
    "            X_test_filtered = pd.concat([X_test_Rest.reset_index(drop=True), X_test_MRI.reset_index(drop=True)], axis=1)\n",
    "            X_AIBL_filtered = pd.concat([X_AIBL_Rest.reset_index(drop=True), X_AIBL_MRI.reset_index(drop=True)], axis=1)\n",
    "            X_OASIS_filtered = pd.concat([X_OASIS_Rest.reset_index(drop=True), X_OASIS_MRI.reset_index(drop=True)], axis=1)\n",
    "            #RandomForest\n",
    "            if(model==\"rf\"):\n",
    "                params = dict()\n",
    "                params['clf__n_estimators'] = skopt.space.space.Integer(250,1250)\n",
    "                params['clf__max_features'] = skopt.space.space.Integer(2,X_train_MRI.shape[1])\n",
    "                params['clf__min_samples_leaf'] = skopt.space.space.Integer(1,20)\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', RandomForestClassifier(random_state=42))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "\n",
    "            if(model==\"xgbTree\"):\n",
    "                params = dict()\n",
    "                params['clf__n_estimators'] = skopt.space.space.Integer(1,500)\n",
    "                params['clf__max_depth'] = skopt.space.space.Integer(1,20)\n",
    "                params['clf__learning_rate'] = skopt.space.space.Real(10e-10,1,prior=\"log-uniform\",base=10)\n",
    "                params['clf__gamma'] = skopt.space.space.Real(0,20)\n",
    "                params['clf__min_child_weight'] = skopt.space.space.Real(1,30)\n",
    "                params['clf__subsample'] = skopt.space.space.Real(0,1)\n",
    "                params['clf__colsample_bytree'] = skopt.space.space.Real(0,1)\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', xgb.XGBClassifier(booster =\"gbtree\",random_state=42))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "            if model==\"rpart\":\n",
    "                params = dict()\n",
    "                params['clf__criterion'] = skopt.space.space.Categorical(['gini', 'entropy'])\n",
    "                params['clf__splitter'] = skopt.space.space.Categorical([\"best\",\"random\"])\n",
    "                params['clf__max_depth'] = skopt.space.space.Integer(1,100)\n",
    "                params['clf__min_samples_split'] = skopt.space.space.Real(0.01,1)\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "\n",
    "            if model==\"svmPoly\":\n",
    "                params = dict()\n",
    "                params['clf__C'] = skopt.space.space.Real(10e-4,10e2,prior=\"log-uniform\",base=10)\n",
    "                params['clf__degree'] = skopt.space.space.Integer(1,10)\n",
    "                params['clf__gamma'] = skopt.space.space.Categorical([\"scale\",\"auto\"])\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', SVC(kernel=\"poly\",random_state=42,probability=True))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "\n",
    "            if model==\"svmRBF\":\n",
    "                params = dict()\n",
    "                params['clf__C'] = skopt.space.space.Real(10e-4,10e2,prior=\"log-uniform\",base=10)\n",
    "                params['clf__gamma'] = skopt.space.space.Categorical([\"scale\",\"auto\"])\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', SVC(kernel=\"rbf\",random_state=42,probability=True))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "            if model==\"logReg\":\n",
    "                params = dict()\n",
    "                params['clf__C'] = skopt.space.space.Real(10e-4,10e2,prior=\"log-uniform\",base=10)\n",
    "                params['clf__penalty'] = skopt.space.space.Categorical([\"l2\", \"none\"])\n",
    "\n",
    "                numeric_features = X_train_filtered.columns.values.tolist()\n",
    "                numeric_transformer = Pipeline(\n",
    "                [\n",
    "                    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "                )\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                    ('numericals', numeric_transformer, numeric_features)\n",
    "                ],\n",
    "                remainder = 'drop'\n",
    "                )\n",
    "\n",
    "                pipeline = Pipeline(\n",
    "                [\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('clf', LogisticRegression(random_state=42))\n",
    "                ]\n",
    "                )\n",
    "\n",
    "\n",
    "                rskf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 42)\n",
    "\n",
    "                cv = BayesSearchCV(estimator=pipeline,n_iter=25,search_spaces= params, cv = rskf, n_jobs = -1,optimizer_kwargs={'initial_point_generator': \"lhs\",\"n_initial_points\":10,\"acq_func\": \"LCB\"},random_state=50,return_train_score=True ,scoring='accuracy')\n",
    "                cv.fit(X_train_filtered, y_train)\n",
    "            joblib.dump(cv, '/path_to_save_model/model_'+featureSetSelected+\"_\"+model+\"_\"+selectMethod+'.pkl', compress = 1)\n",
    "            pred=cv.predict(X_test_filtered)\n",
    "            pred_prob=cv.predict_proba(X_test_filtered)\n",
    "            accADNI=np.round_(accuracy_score(y_test, pred),decimals=4)*100\n",
    "            BACCADNI=np.round_(balanced_accuracy_score(y_test, pred),decimals=4)*100\n",
    "            AUROCADNI=np.round_(roc_auc_score(y_test, pred_prob[:,1],average=\"macro\"),decimals=4)*100\n",
    "            F1ADNI=np.round_(f1_score(y_test, pred, average='macro'),decimals=4)*100\n",
    "            MCCADNI=np.round_(matthews_corrcoef(y_test, pred),decimals=3)\n",
    "            \n",
    "            predAIBL=cv.predict(X_AIBL_filtered)\n",
    "            pred_prob_AIBL=cv.predict_proba(X_AIBL_filtered)\n",
    "            accAIBL=np.round_(accuracy_score(y_AIBL, predAIBL),decimals=4)*100\n",
    "            BACCAIBL=np.round_(balanced_accuracy_score(y_AIBL, predAIBL),decimals=4)*100\n",
    "            AUROCAIBL=np.round_(roc_auc_score(y_AIBL, pred_prob_AIBL[:,1],average=\"macro\"),decimals=4)*100\n",
    "            F1AIBL=np.round_(f1_score(y_AIBL, predAIBL, average='macro'),decimals=4)*100\n",
    "            MCCAIBL=np.round_(matthews_corrcoef(y_AIBL, predAIBL),decimals=3)\n",
    "            \n",
    "            predOASIS=cv.predict(X_OASIS_filtered)\n",
    "            pred_prob_OASIS=cv.predict_proba(X_OASIS_filtered)\n",
    "            accOASIS=np.round_(accuracy_score(y_OASIS, predOASIS),decimals=4)*100\n",
    "            BACCOASIS=np.round_(balanced_accuracy_score(y_OASIS, predOASIS),decimals=4)*100\n",
    "            AUROCOASIS=np.round_(roc_auc_score(y_OASIS, pred_prob_OASIS[:,1],average=\"macro\"),decimals=4)*100\n",
    "            F1OASIS=np.round_(f1_score(y_OASIS, predOASIS, average='macro'),decimals=4)*100\n",
    "            MCCOASIS=np.round_(matthews_corrcoef(y_OASIS, predOASIS),decimals=3)\n",
    "            \n",
    "            sdCV=np.round_(cv.cv_results_['std_test_score'][cv.best_index_],decimals=4)*100 \n",
    "\n",
    "            meanCV=np.round_(cv.cv_results_['mean_test_score'][cv.best_index_],decimals=4)*100\n",
    "            d = {\"selectMethod\":[selectMethod],\"featureSetSelected\":[featureSetSelected],'model': [model],'params': [json.dumps(cv.best_params_)], 'Mean CV Accuracy':[meanCV], 'Sd CV Accuracy':[sdCV], \"ACCADNI\":[accADNI], \"BACCADNI\":[BACCADNI], \"AUROCADNI\":[AUROCADNI], \"F1ADNI\":[F1ADNI], \"MCCADNI\":[MCCADNI], \"ACCAIBL\":[accAIBL], \"BACCAIBL\":[BACCAIBL], \"AUROCAIBL\":[AUROCAIBL], \"F1AIBL\":[F1AIBL], \"MCCAIBL\":[MCCAIBL], \"ACCOASIS\":[accOASIS], \"BACCOASIS\":[BACCOASIS], \"AUROCOASIS\":[AUROCOASIS], \"F1OASIS\":[F1OASIS], \"MCCOASIS\":[MCCOASIS]}\n",
    "            df = pd.DataFrame(data=d)\n",
    "            if os.path.isfile(filenameCSV):\n",
    "                df.to_csv(filenameCSV, mode='a', header=False)\n",
    "            else:\n",
    "                df.to_csv(filenameCSV, mode='w', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
